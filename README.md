

##Grad16

Grad16 is a lightweight, minimalistic automatic differentiation library for machine learning. It provides a simple way to build and train neural networks using a computational graph with backpropagation support.
It is mostly designed to work with my fp16 CUDA kernels and is not intended for production at all. Just a hobby project that i enjoy working on.
I was frustrated with how pytorch handles fp16 training and wanted to make my own library that is simple and easy to understand. I also wanted to learn more about how automatic differentiation works under the hood.






